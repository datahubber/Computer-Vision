Capstone project: Hand gesture tracking in videos  
The game "Guess Which Hand" is a simple game where one player hides an object in one of their hands, then presents both hands to another player to guess which one holds the object. This research aims to train an AI model to recognize body postures, hand positions, and subtle movements, using this game as a basis for developing posture recognition capabilities. The project’s input would be video or image data capturing players' postures and hand movements during the game, while the output would be predictions indicating the likely hand holding the object. The apprentice researcher will receive essential resources, including a labeled dataset capturing various postures and hand positions. This dataset will consist of images or video frames annotated with key body and hand landmarks. The project will involve several training steps: first, preprocessing the dataset, including annotation and augmentation to ensure robust model performance across different scenarios. Next, a deep learning model (such as YOLO, HRNet or OpenPose) for pose estimation—will be trained on this data, using frameworks like TensorFlow or PyTorch. Iterative training and validation steps will allow for adjustments and improvements to model accuracy. The project requires skills in computer vision, machine learning, and programming, with experience in data annotation and motion tracking as advantageous. Video example: https://www.youtube.com/shorts/_twFdZ0LYuU
